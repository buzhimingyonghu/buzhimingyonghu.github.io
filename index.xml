<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Victor的世界</title>
    <link>//localhost:1313/</link>
    <description>Recent content on Victor的世界</description>
    <generator>Hugo</generator>
    <language>zh</language>
    <lastBuildDate>Tue, 18 Feb 2025 19:42:02 +0800</lastBuildDate>
    <atom:link href="//localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PacificA 一致性测试用例说明</title>
      <link>//localhost:1313/posts/zh/pika/pacifica-test-cases/</link>
      <pubDate>Tue, 18 Feb 2025 19:42:02 +0800</pubDate>
      <guid>//localhost:1313/posts/zh/pika/pacifica-test-cases/</guid>
      <description>&lt;h2 id=&#34;测试用例1基础一致性测试&#34;&gt;测试用例1：基础一致性测试&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;目的&lt;/strong&gt;：验证主从复制的基本功能和数据一致性&#xA;&lt;strong&gt;步骤&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;向主节点写入数据&lt;/li&gt;&#xA;&lt;li&gt;验证两个从节点的数据同步情况&lt;/li&gt;&#xA;&lt;li&gt;检查所有节点的复制状态&#xA;&lt;strong&gt;预期结果&lt;/strong&gt;：所有节点数据完全一致，复制状态正常&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;测试用例2并发写入一致性测试&#34;&gt;测试用例2：并发写入一致性测试&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;目的&lt;/strong&gt;：确保并发写入时的数据一致性&#xA;&lt;strong&gt;步骤&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;向主节点并发写入10条数据&lt;/li&gt;&#xA;&lt;li&gt;等待数据同步完成&lt;/li&gt;&#xA;&lt;li&gt;验证两个从节点的所有数据&#xA;&lt;strong&gt;预期结果&lt;/strong&gt;：所有并发写入的数据都正确同步到从节点&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;测试用例3网络分区恢复测试&#34;&gt;测试用例3：网络分区恢复测试&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;目的&lt;/strong&gt;：测试网络分区后的一致性恢复&#xA;&lt;strong&gt;步骤&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;写入初始数据&lt;/li&gt;&#xA;&lt;li&gt;断开从节点1连接（模拟网络分区）&lt;/li&gt;&#xA;&lt;li&gt;向主节点写入新数据&lt;/li&gt;&#xA;&lt;li&gt;恢复从节点1连接&lt;/li&gt;&#xA;&lt;li&gt;验证数据一致性&#xA;&lt;strong&gt;预期结果&lt;/strong&gt;：网络恢复后，断开的从节点应同步所有错过的数据&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;测试用例4动态节点添加测试&#34;&gt;测试用例4：动态节点添加测试&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;目的&lt;/strong&gt;：验证新增节点时的数据一致性&#xA;&lt;strong&gt;步骤&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;初始只启动主节点和一个从节点&lt;/li&gt;&#xA;&lt;li&gt;写入一批初始数据&lt;/li&gt;&#xA;&lt;li&gt;添加第二个从节点&lt;/li&gt;&#xA;&lt;li&gt;写入新的数据&lt;/li&gt;&#xA;&lt;li&gt;验证新旧数据的一致性&#xA;&lt;strong&gt;预期结果&lt;/strong&gt;：新加入的从节点应正确接收所有历史数据和新数据&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;测试用例5节点故障恢复测试&#34;&gt;测试用例5：节点故障恢复测试&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;目的&lt;/strong&gt;：测试节点故障和恢复时的系统行为&#xA;&lt;strong&gt;步骤&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;向所有节点写入初始数据&lt;/li&gt;&#xA;&lt;li&gt;模拟从节点1故障&lt;/li&gt;&#xA;&lt;li&gt;故障期间写入数据&lt;/li&gt;&#xA;&lt;li&gt;恢复从节点1&lt;/li&gt;&#xA;&lt;li&gt;写入新的数据&lt;/li&gt;&#xA;&lt;li&gt;验证所有数据集&#xA;&lt;strong&gt;预期结果&lt;/strong&gt;：&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;节点故障期间系统继续正常运行&lt;/li&gt;&#xA;&lt;li&gt;故障节点恢复后能同步所有错过的数据&lt;/li&gt;&#xA;&lt;li&gt;所有节点最终达到数据一致&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;测试环境&#34;&gt;测试环境&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;1个主节点（端口：9301）&lt;/li&gt;&#xA;&lt;li&gt;2个从节点（端口：9302，9303）&lt;/li&gt;&#xA;&lt;li&gt;启用强一致性模式&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;注意事项&#34;&gt;注意事项&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;每个测试用例都包含足够的等待时间，确保数据同步完成&lt;/li&gt;&#xA;&lt;li&gt;所有测试都在强一致性模式下进行&lt;/li&gt;&#xA;&lt;li&gt;测试过程中会验证数据的完整性和一致性&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>PacificA解读</title>
      <link>//localhost:1313/posts/zh/distributed/pacifica-test-cases/</link>
      <pubDate>Tue, 18 Feb 2025 19:42:02 +0800</pubDate>
      <guid>//localhost:1313/posts/zh/distributed/pacifica-test-cases/</guid>
      <description>&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;&#xA;&lt;p&gt;大规模分布式存储因数据量增长而广受关注，复制机制是实现高可用性和高吞吐的关键。尽管共识研究为复制协议奠定基础，但架构设计和工程实现仍具挑战。本文分享了PacificA协议基于日志的存储系统设计复制机制的经验，提出一种简单、实用、强一致的通用复制框架，展示其支持多种设计选择的灵活性。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;1-pacifica-流程&#34;&gt;1. PacificA 流程&lt;/h1&gt;&#xA;&lt;p&gt;系统通过主从模式实现数据复制，每份数据由一个副本组负责，组内指定主服务器，其余为备份，配置变化由版本号跟踪。本文关注强一致性复制协议，确保分布式系统行为与单机一致（线性一致性）。&lt;/p&gt;&#xA;&lt;h2 id=&#34;11-主从复制&#34;&gt;1.1 主从复制&lt;/h2&gt;&#xA;&lt;p&gt;我们将客户端请求分为两类：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;读数据的查询请求&lt;/li&gt;&#xA;&lt;li&gt;写数据的更新请求。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;如果复制组中的所有服务器以相同顺序处理相同的请求集（假设更新是确定性的），则可以实现强一致性。因此，主服务器为更新分配连续且单调递增的序列号，并指示所有备服务器按此顺序连续处理请求。&lt;/p&gt;&#xA;&lt;h3 id=&#34;正常情况下的处理流程&#34;&gt;正常情况下的处理流程：&lt;/h3&gt;&#xA;&lt;h4 id=&#34;读请求的处理&#34;&gt;读请求的处理：&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;当主服务器接收到读请求时，它直接使用当前提交列表中（未实现）记录的状态来处理请求。查询请求不影响数据的一致性，因此主服务器可以立刻返回结果。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;写请求的处理&#34;&gt;写请求的处理：&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;主服务器会为写请求分配一个递增的全局序列号，确保所有请求按照固定的顺序处理。&lt;/li&gt;&#xA;&lt;li&gt;主服务器会将包含配置版本（未实现）和序列号的请求和CommittedID，通过一个 &lt;code&gt;prepare&lt;/code&gt; 消息发送给所有从服务器。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;从服务器的处理&#34;&gt;从服务器的处理：&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每个备服务器在收到 &lt;code&gt;prepare&lt;/code&gt; 消息后，会按照序列号顺序将请求添加到自己的准备列表中，将请求标记为“已准备”。&lt;/li&gt;&#xA;&lt;li&gt;随后，备服务器向主服务器发送一个 &lt;code&gt;prepared&lt;/code&gt; 消息作为确认。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;提交到状态机&#34;&gt;提交到状态机：&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;当主服务器收到所有从服务器的确认后，才会将该请求标记为已提交。此时，主服务器更新它的提交点，使其指向已提交的最高序列号位置。&lt;/li&gt;&#xA;&lt;li&gt;主服务器会向客户端返回确认消息，表示请求已成功完成。&lt;/li&gt;&#xA;&lt;li&gt;在每次发送 &lt;code&gt;prepare&lt;/code&gt; 消息时，主服务器还会附带当前提交点的序列号，告知备服务器哪些请求已经提交。这样，备服务器可以将自己的提交点前移，与主服务器保持一致。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;一致性保证&#34;&gt;一致性保证：&lt;/h3&gt;&#xA;&lt;p&gt;主服务器仅在所有从服务器将请求添加到准备列表后，才会将其加入提交列表，确保提交列表与备服务器的准备列表一致且包含于其中。同时，从服务器仅在主服务器标记请求为提交后，才会将其视为已提交，确保备服务器的提交列表始终包含于主服务器的提交范围内。&lt;/p&gt;&#xA;&lt;h3 id=&#34;提交-invariant&#34;&gt;提交 Invariant：&lt;/h3&gt;&#xA;&lt;p&gt;形成了“提交 Invariant”，即对于主服务器 &lt;code&gt;p&lt;/code&gt; 和任何备服务器 &lt;code&gt;q&lt;/code&gt;，始终有：&lt;/p&gt;&#xA;&lt;p&gt;committedq ⊆ committedp ⊆ preparedq&lt;/p&gt;&#xA;&lt;p&gt;这保证了主备之间的数据一致性和同步。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;12-配置管理&#34;&gt;1.2 配置管理&lt;/h2&gt;&#xA;&lt;h3 id=&#34;设计一个全局配置管理器&#34;&gt;设计一个全局配置管理器：&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;负责管理和维护系统中所有副本组的配置。&lt;/li&gt;&#xA;&lt;li&gt;对于每个副本组，配置管理器会保存当前的配置和配置版本。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;全局配置管理器的功能&#34;&gt;全局配置管理器的功能：&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;重新配置&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;检测副本是否出现故障，决定是否移除副本，或者重启副本配置。&lt;/li&gt;&#xA;&lt;li&gt;添加新的副本。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;增添从节点&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;根据设定的规则决定是否添加新配置。&lt;/li&gt;&#xA;&lt;li&gt;配置规则：是否版本匹配，检测副本的 &lt;code&gt;committedID&lt;/code&gt; 是否匹配（是否存在，是否小于主的 &lt;code&gt;committedID&lt;/code&gt;）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;主崩溃后，重新配置&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果发生网络分区，导致主服务器与副本之间断开连接，可能会出现冲突的重新配置请求。例如，主服务器可能希望移除一些副本，而某些副本则希望移除主服务器。&lt;/li&gt;&#xA;&lt;li&gt;依旧先检测是否匹配规则 &lt;code&gt;L&lt;/code&gt;，匹配成功后配置管理器接受的请求会“胜出”。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;故障检测和主服务器不变性&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;主服务器不变性要求，在任何时刻，服务器 &lt;code&gt;p&lt;/code&gt; 只有在配置管理器认为它是当前配置中的主服务器时，才会将自己视为主服务器。这样可以确保在系统中，副本组中最多只有一台服务器会认为自己是主服务器。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;总结&#34;&gt;总结：&lt;/h3&gt;&#xA;&lt;p&gt;配置管理器负责协调和维护系统的配置，确保副本组的配置一致性、版本控制和故障恢复。主服务器不变性确保在系统中始终只有一个主服务器，而不会发生多个服务器同时作为主服务器的情况。&lt;/p&gt;</description>
    </item>
    <item>
      <title>基于PacificA协议Pika主从一致性</title>
      <link>//localhost:1313/posts/zh/pika/pacifica-consistency/</link>
      <pubDate>Tue, 18 Feb 2025 19:42:02 +0800</pubDate>
      <guid>//localhost:1313/posts/zh/pika/pacifica-consistency/</guid>
      <description>&lt;h1 id=&#34;pacifica-协议概述&#34;&gt;PacificA 协议概述&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2008/02/tr-2008-25.pdf&#34;&gt;PacificA &lt;/a&gt;协议简单来说分为两部分：&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;- 数据复制&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;配置管理&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;em&gt;由于在 Pika 中，配置管理主要由 &lt;code&gt;pika_sentinel&lt;/code&gt; 负责，本文主要关注通过主从模式的数据复制及其与 &lt;code&gt;pika_sentinel&lt;/code&gt; 配合的协调过程。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;在-pika-中的应用&#34;&gt;在 Pika 中的应用&lt;/h2&gt;&#xA;&lt;p&gt;主要分为三个部分：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;PacificA 中主从模式的数据一致流程处理&lt;/li&gt;&#xA;&lt;li&gt;分布式日志型存储系统的设计&lt;/li&gt;&#xA;&lt;li&gt;故障恢复后的协调状态&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;启动-pacifica&#34;&gt;启动 PacificA&lt;/h2&gt;&#xA;&lt;p&gt;在 Pika 中，建立普通主从连接的命令为：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;slaveof &amp;lt;ip&amp;gt; &amp;lt;port&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果需要启动 PacificA 协议，需要增加 strong 参数：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;slaveof &amp;lt;ip&amp;gt; &amp;lt;port&amp;gt; strong&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当从节点执行上述命令时，会触发 slaveofcmd，读取相关参数，并由 pika_server 保存这些信息，随后异步交由 PikaAuxiliaryThread 线程（以下简称 PAT）处理。&#xA;PAT 是 PacificA 协议中的核心辅助线程，负责：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;- 状态机状态切换&#xA;- 主从之间的心跳发送及超时检查&#xA;- 主从之间的同步任务&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;pacifica-主从模式的数据一致流程&#34;&gt;PacificA 主从模式的数据一致流程&lt;/h2&gt;&#xA;&lt;h3 id=&#34;主从建立连接的四个阶段&#34;&gt;主从建立连接的四个阶段&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;MetaSync：主从元数据的同步和检查&lt;/li&gt;&#xA;&lt;li&gt;TrySync：判断数据完整性，选择全量同步或增量同步&lt;/li&gt;&#xA;&lt;li&gt;Candidate：从节点作为候选者，追加完整的准备列表&lt;/li&gt;&#xA;&lt;li&gt;BinlogSync：正式加入集群，开始进行数据复制&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/11268449-19db-4d14-af3b-0aebd9e54a54&#34; alt=&#34;image&#34;&gt;&#xA;下面是基本的数据结构：&#xA;&lt;img src=&#34;https://github.com/user-attachments/assets/d81d704d-34ce-4c8e-aaff-d4f137a45035&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;metasync-阶段&#34;&gt;MetaSync 阶段&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/19e287da-0630-4381-b09e-75527ea76a20&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;从节点的 PAT 线程通过发送 MetaReq 请求与主节点建立连接，其中包含 is_consistency 字段，表示强一致性请求。&#xA;主节点收到请求后，若 consistency 标记为 true，则会：&lt;/p&gt;</description>
    </item>
    <item>
      <title>关于我</title>
      <link>//localhost:1313/about/</link>
      <pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/about/</guid>
      <description>&lt;h1 id=&#34;-你好我是-刘恒胜&#34;&gt;👋 你好，我是 刘恒胜&lt;/h1&gt;&#xA;&lt;p&gt;来自西安财经大学 信息工程学院 网络工程专业&lt;/p&gt;&#xA;&lt;h2 id=&#34;-工作经历&#34;&gt;💼 工作经历&lt;/h2&gt;&#xA;&lt;h3 id=&#34;奇虎360北京总部&#34;&gt;奇虎360(北京总部)&lt;/h3&gt;&#xA;&lt;p&gt;&lt;em&gt;Pika是一个高性能、高容量、多租户的KV存储系统，支持数据持久化，完全兼容Redis协议，已在GitHub上获得超过5.9k stars。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h4 id=&#34;pika-主从一致性开发&#34;&gt;Pika 主从一致性开发：&lt;/h4&gt;&#xA;&lt;p&gt;&lt;em&gt;pika主从复制采用异步追赶复制，在遇到主节点故障后，重新选主后的主节点可能不具备完整的数据，故在对数据完整性要求高的场景，需要采用强一致性协议，在和团队成员讨论后，由我独立负责PacificA协议进行一致性开发。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;PacificA 主从数据一致性流程&lt;/strong&gt; :重新设计主从数据交互的全链路处理流程，包含进行主从元数据同步MetaSync，确保主从一致性标记、数据完整性检查TrySync、进行全量或增量同步、从作为Candidate、追加完整的准备列表、BinlogSync通过日志和心跳包确保数据复制四个核心阶段。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;采用逻辑复制方式&lt;/strong&gt;:主节点负责日志追加并确保提交点前移，从节点按照提交点进行数据写入，保证主从一致性。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;分布式日志存储系统开发&lt;/strong&gt;:先将数据写入日志，再更新内存数据结构，并定期创建检查点防止日志无限增长。创建检查点后进行日志截断，减少存储压力。在系统崩溃时，可利用日志回放机制恢复数据，保证高可用性。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;故障恢复与状态协调&lt;/strong&gt;:重新选举新的主节点时，将所有副本的 preparedID 对齐新主节点的preparedID。新主节点提交所有已准备的日志，使 preparedID 和 committedID 一致，保证日志完整性。写请求流程：先写 binlog，等待所有从节点追加日志后，再执行数据库写入，确保数据不会丢失或回滚失败。超时则记录异常退出，保障系统在恢复后仍具备数据一致性和高可用性，确保在 n-1 节点故障时仍具备容错能力。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;pika-operator开发&#34;&gt;Pika-Operator开发&lt;/h4&gt;&#xA;&lt;p&gt;&lt;em&gt;Pika-Operator主要采用kubeblocks进行开发，提供了去中心化，模块化架构，并具有两种集群模式，集群部署，动态扩缩容。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;主从集群优化与升级&lt;/strong&gt;:基于最新的Operator升级K8s集群，添加 Role 模块并优化 Pika 主从流程，解决部分 Pod 失效问题。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;备份与恢复组件&lt;/strong&gt;:学习Pika的Bgsave流程，完成BackupPolicy，并结合CSI配置并连接S3，实现了自动备份与恢复。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;解决dba线上遇到的bug&#34;&gt;解决DBA线上遇到的BUG：&lt;/h4&gt;&#xA;&lt;p&gt;解决了ACl中普通用户无权限问题，开发pika-export版本管理，协助解决快慢命令时间统计问题。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;个人总结&lt;/strong&gt;: 我深入研究了系统源码，对pika多线程模型，主从架构了清晰的认识，深入学习了Kubernetes，docker及Operator相关知识，研读并总结了微软的PacificA论文，并与团队成员积极讨论。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-开源贡献&#34;&gt;🌟 开源贡献&lt;/h2&gt;&#xA;&lt;h3 id=&#34;腾讯犀牛鸟计划---负载均衡插件开发&#34;&gt;腾讯犀牛鸟计划 - 负载均衡插件开发&lt;/h3&gt;&#xA;&lt;p&gt;&lt;em&gt;issue描述：实现IP直连负载均衡插件 - 加权轮询算法，通过分配权重，将请求分配到不同服务器上，尽可能提高集群的处理请求量&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;SWRR 通过在每轮分配时调整服务器权重，避免短时间内的负载集中，使得服务器的请求数量与其权重成比例。编写单元测试，通过了异步选择、以及动态端点的处理等场景.&lt;/p&gt;&#xA;&lt;h3 id=&#34;阿里天池云原生挑战赛---oceanbase&#34;&gt;阿里天池云原生挑战赛 - OceanBase&lt;/h3&gt;&#xA;&lt;p&gt;&lt;em&gt;issue描述：oblogminer 在处理 obcdc 输出的结果时，对于无法判断的列值，通常会使用标记来表示这些列值可能不准确&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;修复了源于日志LOB类型为NULL标记不准确，修复了MINIMAL模式下，其他列类型也可能产生不可靠的结果，代码现在检查每个列值的来源&lt;/p&gt;&#xA;&lt;h2 id=&#34;-项目经历&#34;&gt;🚀 项目经历&lt;/h2&gt;&#xA;&lt;h3 id=&#34;bustub-vectordb-向量数据库开发&#34;&gt;Bustub Vectordb 向量数据库开发&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;2024.10 - 2024.11&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Bustub_Vectordb一个基于 CMU-DB 的 BusTub 系统，支持向量存储、相似检索的关系型数据库&lt;/em&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
